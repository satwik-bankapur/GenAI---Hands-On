{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Part 3a: Chain of Thought (CoT)\n",
        "\n",
        "## 1. Introduction: The Inner Monologue\n",
        "\n",
        "Standard LLMs try to jump straight to the answer. For complex problems (math, logic), this often fails.\n",
        "\n",
        "**Chain of Thought (CoT)** forces the model to \"think out loud\" before answering.\n",
        "\n",
        "### Why use a \"Dumb\" Model?\n",
        "For this unit, we will use **Llama3.1-8b** (via Groq). It is a smaller, faster model.\n",
        "Why? Because huge models (like Gemini Pro or GPT-4) are often *too smart*—they solve logic riddles instantly without thinking.\n",
        "\n",
        "To really see the power of Prompt Engineering, we need a model that **needs help**.\n",
        "\n",
        "### Visualizing the Process (Flowchart)\n",
        "```mermaid\n",
        "graph TD\n",
        "    Input[Question: 5+5*2?]\n",
        "    Input -->|Standard| Wrong[Answer: 20 (Wrong)]\n",
        "    Input -->|CoT| Step1[Step 1: 5*2=10]\n",
        "    Step1 --> Step2[Step 2: 5+10=15]\n",
        "    Step2 --> Correct[Answer: 15 (Correct)]\n",
        "```"
      ],
      "metadata": {
        "id": "rE8XE1b3naoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Concept: Latent Reasoning\n",
        "\n",
        "Why does this work?\n",
        "Because LLMs are \"Next Token Predictors\".\n",
        "- If you force it to answer immediately, it must predict the digits `1` and `5` immediately.\n",
        "- If you let it \"think\", it generates intermediate tokens (`5`, `*`, `2`, `=`, `1`, `0`).\n",
        "- The model then **ATTENDS** to these new tokens to compute the final answer.\n",
        "\n",
        "**Writing is Thinking.**"
      ],
      "metadata": {
        "id": "ePK1Hk5anf05"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25z8biHsmdiy",
        "outputId": "922cbf32-eeb1-44a6-c35e-a8260ed74442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m102.4/111.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m102.4/111.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hEnter your Groq API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b (Small/Fast) to demonstrate logic failures\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. The Experiment: A Tricky Math Problem\n",
        "\n",
        "Let's try a problem that requires multi-step logic.\n",
        "\n",
        "**Problem:**\n",
        "\"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many does he have now?\""
      ],
      "metadata": {
        "id": "pn8RSzwXnzpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Emma has 8 notebooks. She buys 15 packs of notebooks. Each pack contains 4 notebooks. Then she gives 5 notebooks to her friend. How many notebooks does she have left?\"\n",
        "\n",
        "# 1. Standard Prompt (Direct Answer)\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_standard).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj5tphzgnirS",
        "outputId": "c75f3bf1-5404-4d1b-8d40-87eea2259845"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD (Llama3.1-8b) ---\n",
            "To find out how many notebooks Emma has left, we need to calculate the total number of notebooks she has after buying and then subtract the number she gave to her friend.\n",
            "\n",
            "Emma starts with 8 notebooks.\n",
            "\n",
            "She buys 15 packs of notebooks, each containing 4 notebooks. \n",
            "15 packs * 4 notebooks/pack = 60 notebooks\n",
            "\n",
            "Now, Emma has 8 + 60 = 68 notebooks.\n",
            "\n",
            "Then, she gives 5 notebooks to her friend. \n",
            "68 - 5 = 63 notebooks\n",
            "\n",
            "So, Emma has 63 notebooks left.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Critique\n",
        "Smaller models often latch onto the visible numbers (5 and 2) and simply add them (7), ignoring the multiplication step implied by \"cans\".\n",
        "\n",
        "Let's force it to think."
      ],
      "metadata": {
        "id": "BQxEEK3nn3g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. CoT Prompt (Magic Phrase)\n",
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_cot).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMP8iGr5n1rA",
        "outputId": "5bce338f-d797-4e87-cde7-e6f90e7f2378"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chain of Thought (Llama3.1-8b) ---\n",
            "To find out how many notebooks Emma has left, we need to follow the steps:\n",
            "\n",
            "1. Emma starts with 8 notebooks.\n",
            "2. She buys 15 packs of notebooks, and each pack contains 4 notebooks. So, she buys 15 * 4 = 60 notebooks.\n",
            "3. Now, Emma has 8 (initial notebooks) + 60 (new notebooks) = 68 notebooks.\n",
            "4. She gives 5 notebooks to her friend. So, we subtract 5 from 68: 68 - 5 = 63.\n",
            "\n",
            "Therefore, Emma has 63 notebooks left.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Analysis\n",
        "\n",
        "Look at the output. By explicitly breaking it down:\n",
        "1.  \"Roger starts with 5.\"\n",
        "2.  \"2 cans * 3 balls = 6 balls.\"\n",
        "3.  \"5 + 6 = 11.\"\n",
        "\n",
        "The model effectively \"debugs\" its own logic by generating the intermediate steps."
      ],
      "metadata": {
        "id": "_q4-f--0oEEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Part 3b: Tree of Thoughts (ToT) & Graph of Thoughts (GoT)\n",
        "\n",
        "## 1. Introduction: Beyond A -> B\n",
        "\n",
        "CoT is linear. But complex reasoning is often nonlinear. We need to explore branches (ToT) or even combine ideas (GoT).\n",
        "\n",
        "We continue using **Llama3.1-8b via Groq** to show how structure improves performance."
      ],
      "metadata": {
        "id": "bG_xZDkDoGfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) # Creativity needed"
      ],
      "metadata": {
        "id": "bLljQL51n7Om"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Tree of Thoughts (ToT)\n",
        "\n",
        "ToT explores multiple branches before making a decision.\n",
        "**Analogy:** A chess player considering 3 possible moves before playing one.\n",
        "\n",
        "### Implementation\n",
        "We will generate 3 distinct solutions for a problem and then use a \"Judge\" to pick the best one."
      ],
      "metadata": {
        "id": "ms_u3gW4oKlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can a small startup compete against a large, well-funded competitor?\"\n",
        "\n",
        "# Step 1: Branch Generator (Improved Prompt)\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Problem: {problem}\n",
        "\n",
        "    Generate ONE distinct strategic solution.\n",
        "    It must be fundamentally different from typical answers.\n",
        "    Be specific and actionable.\n",
        "\n",
        "    Strategy {id}:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    strategy1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    strategy2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    strategy3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        "    strategy4=prompt_branch.partial(id=\"4\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# Step 2: Judge with Clear Evaluation Criteria\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are a seasoned Product Manager.\n",
        "\n",
        "    A startup faces this problem:\n",
        "    \"{problem}\"\n",
        "\n",
        "    Here are four strategic approaches:\n",
        "\n",
        "    1: {strategy1}\n",
        "    2: {strategy2}\n",
        "    3: {strategy3}\n",
        "    4: {strategy4}\n",
        "\n",
        "    Evaluate them based on:\n",
        "    - Long-term sustainability\n",
        "    - Competitive defensibility\n",
        "    - Resource efficiency\n",
        "    - Realistic execution feasibility\n",
        "\n",
        "    Pick the strongest strategy and explain your reasoning clearly.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# Step 3: Full Tree of Thoughts Chain\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Enhanced Tree of Thoughts (ToT) Result ---\")\n",
        "print(tot_chain.invoke(problem))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3JMr4LroIm3",
        "outputId": "a27f9068-92b5-41e2-cea2-f1b19c2b3ba2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Enhanced Tree of Thoughts (ToT) Result ---\n",
            "After evaluating the four strategic approaches, I recommend **Strategy 1: \"Reverse Engineer\" the Large Competitor's Success** as the strongest approach. Here's why:\n",
            "\n",
            "**Long-term sustainability:** This strategy allows the small startup to create a unique value proposition by identifying and replicating the most valuable aspects of the large competitor's business, while avoiding direct competition. By focusing on the underlying principles and mechanisms that drive the competitor's success, the startup can create a sustainable competitive advantage.\n",
            "\n",
            "**Competitive defensibility:** By developing a novel implementation that adapts the competitor's strengths to the startup's existing strengths and USPs, the startup can create a unique edge that is difficult for the competitor to replicate. This approach also allows the startup to stay ahead of the competition by continuously monitoring the competitor's evolution and adjusting its strategy accordingly.\n",
            "\n",
            "**Resource efficiency:** This strategy requires the startup to conduct an in-depth analysis of the competitor's business, identify unique selling points, and develop a novel implementation. While this may require significant upfront investment, it can lead to a more efficient use of resources in the long run, as the startup is focusing on areas where it has a competitive advantage.\n",
            "\n",
            "**Realistic execution feasibility:** This strategy is feasible to execute, as it relies on the startup's ability to analyze and replicate the competitor's strengths. The startup can leverage data and insights from the competitor's public information, customer feedback, and market research to inform its strategy. Additionally, the strategy involves developing a novel implementation, which can be done through iterative design and testing, allowing the startup to refine its approach as it goes.\n",
            "\n",
            "**Why the other strategies are not as strong:**\n",
            "\n",
            "* **Strategy 2: \"Reverse Innovation\" through \"Anti-Competitor\" Focus** is a good approach, but it may not be as effective if the competitor identifies and addresses their weaknesses. Additionally, focusing on the anti-competitor advantage may not be enough to create a sustainable competitive advantage.\n",
            "* **Strategy 3: \"The Unseen Edge\" - Focus on Unmapped Customer Needs in Emerging Markets** is a good approach for a startup with limited resources, but it may not be as effective in a highly competitive market where the large competitor has a strong presence.\n",
            "* **Strategy 4: \"Echo-Centric\" Approach - Harnessing the Power of User-Generated Solutions** is an innovative approach, but it may not be as effective in a market where customers are not willing to invest time and effort in creating and sharing solutions.\n",
            "\n",
            "Overall, **Strategy 1: \"Reverse Engineer\" the Large Competitor's Success** is the strongest approach because it allows the small startup to create a unique value proposition by identifying and replicating the most valuable aspects of the large competitor's business, while avoiding direct competition. This approach is sustainable, defensible, and efficient, making it a good choice for a small startup looking to compete against a large, well-funded competitor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Graph of Thoughts (GoT)\n",
        "\n",
        "You asked: **\"Where is Graph of Thoughts?\"**\n",
        "\n",
        "GoT is more complex. It's a network. Information can split, process specific parts, and then **AGGREGATE** back together.\n",
        "\n",
        "### The Workflow (Writer's Room)\n",
        "1.  **Split:** Generate 3 independent story plots (Sci-Fi, Fantasy, Mystery).\n",
        "2.  **Aggregate:** The model reads all 3 and creates a \"Master Plot\" that combines the best elements of each.\n",
        "3.  **Refine:** Polish the Master Plot.\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "   Start(Concept) --> A[Draft 1]\n",
        "   Start --> B[Draft 2]\n",
        "   Start --> C[Draft 3]\n",
        "   A & B & C --> Mixer[Aggregator]\n",
        "   Mixer --> Final[Final Story]\n",
        "```"
      ],
      "metadata": {
        "id": "M3Ecv3nPoOqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "topic = \"Cristiano Roanldo\"\n",
        "\n",
        "# 1️⃣ The Generator (Stronger Divergence)\n",
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Topic: {topic}\n",
        "    Genre: {genre}\n",
        "\n",
        "    Write a compelling 1-sentence movie premise.\n",
        "    Make it vivid, cinematic, and genre-authentic.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_scifi=prompt_draft.partial(genre=\"Sci-Fi\") | llm | StrOutputParser(),\n",
        "    draft_romance=prompt_draft.partial(genre=\"Romantic Drama\") | llm | StrOutputParser(),\n",
        "    draft_thriller=prompt_draft.partial(genre=\"Psychological Thriller\") | llm | StrOutputParser(),\n",
        "    draft_fantasy=prompt_draft.partial(genre=\"Dark Fantasy\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "# 2️⃣ The Aggregator (More Intelligent Convergence)\n",
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Topic: {topic}\n",
        "\n",
        "    You are an award-winning screenwriter.\n",
        "\n",
        "    Here are four genre-specific movie premises:\n",
        "\n",
        "    1. Sci-Fi: {draft_scifi}\n",
        "    2. Romantic Drama: {draft_romance}\n",
        "    3. Psychological Thriller: {draft_thriller}\n",
        "    4. Dark Fantasy: {draft_fantasy}\n",
        "\n",
        "    Create a new high-concept film that:\n",
        "    - Preserves the technological depth of Sci-Fi\n",
        "    - Maintains emotional intensity from Romance\n",
        "    - Incorporates psychological tension\n",
        "    - Adds mythic or surreal fantasy elements\n",
        "\n",
        "    Write one cinematic paragraph (5-7 sentences).\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# 3️⃣ The Graph of Thoughts Chain\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Enhanced Graph of Thoughts (GoT) Result ---\")\n",
        "print(got_chain.invoke(topic))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYFgMrB2oMcR",
        "outputId": "a468fac6-098f-43d8-df13-96a49fdc8f88"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Enhanced Graph of Thoughts (GoT) Result ---\n",
            "Here's a cinematic paragraph for a high-concept film that combines the technological depth of Sci-Fi, emotional intensity of Romance, psychological tension, and mythic fantasy elements:\n",
            "\n",
            "\"In 'Echoes of Glory,' Cristiano Ronaldo finds himself catapulted into a reality-bending realm where the boundaries between past, present, and future are shattered. As he navigates this labyrinthine world, he's confronted by echoes of his former selves, each one representing a different pivotal moment in his storied career. But these echoes are not just manifestations of his own psyche - they're also vessels for a mysterious, AI-driven entity known as 'The Overmind,' which seeks to unlock the secrets of Ronaldo's unparalleled skillset and harness it for its own intergalactic ambitions. As Ronaldo's sense of identity begins to fray, he must choose between embracing his true self and succumbing to the overtures of The Overmind, all while navigating a surreal landscape of ghostly teammates, futuristic stadiums, and eerie landscapes that blur the lines between reality and fantasy. With every step, the stakes grow higher, and Ronaldo's very soul hangs in the balance. Will he find a way to reclaim his essence, or will he become forever trapped in this existential labyrinth, forever bound to the whims of The Overmind?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Summary & Comparison Table\n",
        "\n",
        "| Method | Structure | Best For... | Cost/Latency |\n",
        "|--------|-----------|-------------|--------------|\n",
        "| **Simple Prompt** | Input -> Output | Simple facts, summaries | ⭐ Low |\n",
        "| **CoT (Chain)** | Input -> Steps -> Output | Math, Logic, Debugging | ⭐⭐ Med |\n",
        "| **ToT (Tree)** | Input -> 3x Branches -> Select -> Output | Strategic decisions, Brainstorming | ⭐⭐⭐ High |\n",
        "| **GoT (Graph)** | Input -> Branch -> Mix/Aggregate -> Output | Creative Writing, Research Synthesis | ⭐⭐⭐⭐ V. High |\n",
        "\n",
        "**Recommendation:** Start with CoT. Only use ToT/GoT if CoT fails."
      ],
      "metadata": {
        "id": "2v6btxr8ocOk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_zelQGreoZyy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}