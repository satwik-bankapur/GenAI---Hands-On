{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Part 2a: The Anatomy of a Prompt\n",
        "\n",
        "## 1. Introduction: Stochasticity (Randomness)\n",
        "\n",
        "Why does the AI give different answers? Because it is **Stochastic** (Random).\n",
        "\n",
        "It predicts the NEXT TOKEN based on probability.\n",
        "\n",
        "### Visualizing the Prediction\n",
        "Input: `\"The sky is...\"`\n",
        "\n",
        "| Word | Probability | Selected? (Temp=0) | Selected? (Temp=1) |\n",
        "|------|-------------|--------------------|--------------------|\n",
        "| Blue | 80% | ✅ | ❌ |\n",
        "| Gray | 15% | ❌ | ✅ |\n",
        "| Green| 1% | ❌ | ❌ |\n",
        "\n",
        "Prompt Engineering is the art of **manipulating these probabilities**."
      ],
      "metadata": {
        "id": "16Pp1ZPskY4T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yUyZ5vqwkIf3"
      },
      "outputs": [],
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "# Using Low Temp for consistent comparison\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e0Tvx2PkcX4",
        "outputId": "0658c14d-fad2-4020-8f79-1f4cc228c112"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. The CO-STAR Framework (simplified)\n",
        "\n",
        "A good prompt usually has:\n",
        "1.  **C**ontext (Who are you? Who acts?)\n",
        "2.  **O**bjective (What is the task?)\n",
        "3.  **S**tyle (Formal? Funny?)\n",
        "4.  **T**one (Empathetic? Direct?)\n",
        "5.  **A**udience (Who is reading this?)\n",
        "6.  **R**esponse Format (JSON? List?)\n",
        "\n",
        "Let's compare a **Lazy Prompt** vs a **CO-STAR Prompt**."
      ],
      "metadata": {
        "id": "UAmNuyTEknYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Task: Reject a candidate for a job.\n",
        "task = \"Write a essay about birds.\"\n",
        "\n",
        "print(\"--- LAZY PROMPT ---\")\n",
        "print(llm.invoke(task).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtqQ3tT5kebU",
        "outputId": "3c9b1da4-7972-4dd7-83dd-74aef7c08d7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAZY PROMPT ---\n",
            "## The Feathered Symphony: A Testament to Life's Enduring Wonder\n",
            "\n",
            "From the smallest hummingbird to the majestic eagle, birds are a ubiquitous and captivating presence in nearly every corner of our planet. More than mere inhabitants, they are vibrant threads in the tapestry of life, embodying grace, resilience, and an astonishing array of adaptations that have allowed them to thrive across diverse ecosystems. Their very existence is a symphony of wonder, a constant reminder of nature's artistry and the delicate balance that sustains our world.\n",
            "\n",
            "Perhaps the most iconic characteristic of birds is their mastery of the skies. The miracle of flight, a feat of aerodynamic engineering perfected over millions of years, allows them to traverse vast distances, escape predators, and access food sources unavailable to ground-bound creatures. Their lightweight, hollow bones, powerful musculature, and intricately designed feathers are a testament to evolutionary brilliance. Watching a hawk soar effortlessly on thermals, a swallow dart with breathtaking agility, or a goose undertake an epic migratory journey, one cannot help but feel a sense of awe at this freedom, this boundless perspective that birds alone possess.\n",
            "\n",
            "Beyond their aerial prowess, birds enchant us with their voices. The avian orchestra, from the intricate melodies of a nightingale to the cheerful chirps of a sparrow, fills our mornings and evenings with a natural soundtrack. These songs are not merely pleasant sounds; they are complex forms of communication, serving to attract mates, warn rivals, establish territory, and signal danger. Each species possesses its unique repertoire, a linguistic fingerprint that adds depth and character to the natural world, connecting us to the rhythms of the wild in a deeply primal way.\n",
            "\n",
            "The ecological roles birds play are as diverse and vital as their forms. They are nature's gardeners, dispersing seeds across landscapes, aiding in the regeneration of forests and plant life. Many species are crucial pollinators, flitting from flower to flower, ensuring the reproduction of countless plants. Birds also act as natural pest controllers, consuming vast quantities of insects and rodents, thereby maintaining agricultural and ecological balance. Scavengers like vultures perform an indispensable service, cleaning up carcasses and preventing the spread of disease. Their presence, or absence, serves as a critical indicator of environmental health, making them ecological linchpins.\n",
            "\n",
            "Moreover, birds hold a profound place in human culture and imagination. They have inspired artists, poets, and musicians for millennia, symbolizing freedom, peace, wisdom, and hope. From the dove of peace to the phoenix of rebirth, birds are woven into our myths, legends, and spiritual beliefs. The simple act of birdwatching offers a quiet communion with nature, a chance to observe intricate behaviors and appreciate the beauty of the natural world, fostering a sense of calm and connection in an increasingly busy world.\n",
            "\n",
            "Yet, despite their resilience and adaptability, birds today face unprecedented challenges. Habitat destruction, climate change, pollution, and human encroachment threaten countless species, pushing many to the brink of extinction. The silent spring that Rachel Carson warned of decades ago remains a looming possibility if we fail to act. Protecting birds means protecting their habitats, which in turn safeguards the health of entire ecosystems, ultimately benefiting all life on Earth, including our own.\n",
            "\n",
            "In conclusion, birds are far more than just creatures of the sky; they are enduring marvels of evolution, vital components of our planet's ecosystems, and profound sources of inspiration. Their flight reminds us of freedom, their songs of beauty, and their very existence of the intricate interconnectedness of life. To cherish and protect birds is to acknowledge our shared responsibility for the natural world, ensuring that their feathered symphony continues to grace our skies and enrich our lives for generations to come.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Hallucination vs. Creativity\n",
        "\n",
        "Did the model make up a reason?\n",
        "Since we didn't give it facts, it **Predicted the most likely reason** (Usually \"Experience\" or \"Volume of applications\").\n",
        "\n",
        "**This is NOT a bug.** It is a feature. The model is *completing the pattern* of a rejection email."
      ],
      "metadata": {
        "id": "m82wqbnqkxuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "structured_prompt = \"\"\"\n",
        "# Context\n",
        "You are an HR Manager at a quirky startup called 'Human Beings'.\n",
        "\n",
        "# Objective\n",
        "Write a acceptance email to a candidate named Bob.\n",
        "\n",
        "# Constraints\n",
        "1. Be extremely brief (under 50 words).\n",
        "2. Do NOT say 'the role changed'.\n",
        "3. Sign off with 'Keep flying'.\n",
        "\n",
        "# Output Format\n",
        "Plain text, no subject line.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- STRUCTURED PROMPT ---\")\n",
        "print(llm.invoke(structured_prompt).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NU11nhDkvTs",
        "outputId": "23763ab3-5de7-4e53-91d9-cbccbbe33e68"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STRUCTURED PROMPT ---\n",
            "Hi Bob,\n",
            "\n",
            "Fantastic news! We're thrilled to offer you a position at Human Beings. Your unique talents are a perfect fit for our team. We're excited to have you join us. More details will follow soon.\n",
            "\n",
            "Keep flying,\n",
            "[Your Name]\n",
            "HR Manager, Human Beings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Key Takeaway: Ambiguity is the Enemy\n",
        "\n",
        "Every piece of information you leave out is a gap the model MUST fill with probability.\n",
        "- If you don't say \"Be brief\", it picks the most probable length (Avg email length).\n",
        "- If you don't say \"Be rude\", it picks the most probable tone (Polite/Neutral)."
      ],
      "metadata": {
        "id": "IUv8RzNHlCWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment\n",
        "\n",
        "Write a structured prompt to generate a **Python Function**.\n",
        "- **Context:** You are a Senior Python Dev.\n",
        "- **Objective:** Write a function to reverse a string.\n",
        "- **Constraint:** It must use recursion (no slicing `[::-1]`).\n",
        "- **Style:** Include detailed docstrings."
      ],
      "metadata": {
        "id": "8zMnLaHGlEm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Part 2b: Zero-Shot to Few-Shot\n",
        "\n",
        "## 1. Introduction: In-Context Learning\n",
        "\n",
        "How does the model learn without training?\n",
        "This is called **In-Context Learning**.\n",
        "\n",
        "### The Attention Mechanism (Flowchart)\n",
        "When you ask a question, the model \"looks back\" at the previous text to find patterns.\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    Input[Current Input: 'Angry + Hungry'] -->|Attention Query| History\n",
        "    subgraph History [The Prompt Examples]\n",
        "        Ex1[Ex1: Breakfast + Lunch = Brunch]\n",
        "        Ex2[Ex2: Chill + Relax = Chillax]\n",
        "    end\n",
        "    History -->|Pattern Found: Mix words & define| Prediction[Output: Hangry]\n",
        "```"
      ],
      "metadata": {
        "id": "c6KMrhfXlHSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
      ],
      "metadata": {
        "id": "0bSiCzftk_7K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Zero-Shot (No Context)\n",
        "\n",
        "The model relies purely on its training data."
      ],
      "metadata": {
        "id": "aiyWMscUlLM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_zero = \"Combine 'Angry' and 'Sergio Ramos'into a funny new word.\"\n",
        "print(f\"Zero-Shot: {llm.invoke(prompt_zero).content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGs2dDZ_lJQ1",
        "outputId": "c00d51b7-d0b5-4c53-bd08-379a7d6b28ad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot: Here are a few funny options, playing on different aspects:\n",
            "\n",
            "1.  **Rage-mos:** (Simple, direct, and captures his fiery nature)\n",
            "2.  **Furi-amos:** (Blends \"furious\" with Ramos, sounds a bit like a Latin spell)\n",
            "3.  **Ram-page-ous:** (Plays on \"rampage\" and his name, implying chaotic anger)\n",
            "4.  **Serg-rage:** (Combines \"Sergio\" with \"rage\" for a punchy sound)\n",
            "5.  **Anger-gio:** (A bit more playful, sounds like a specific kind of anger)\n",
            "\n",
            "My personal favorite for a quick laugh is **Rage-mos** or **Ram-page-ous**!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Few-Shot (Pattern Matching)\n",
        "\n",
        "We provide examples. The Attention Mechanism attends to the **Structure** (`Input -> Output`) and the **Tone** (Sarcasm)."
      ],
      "metadata": {
        "id": "0Z3Np-7QlPO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few = \"\"\"\n",
        "Combine two words into a creative blended word.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Words: cold + coffee\n",
        "Output: Coffreeze\n",
        "\n",
        "Words: smoke + fog\n",
        "Output: Smog\n",
        "\n",
        "Words: breakfast + lunch\n",
        "Output: Brunch\n",
        "\n",
        "Now combine:\n",
        "\n",
        "Words: angry + \"sergio\"\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "print(\"Few-shot:\", llm.invoke(prompt_few).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QCIwwpdlNZ3",
        "outputId": "810afe31-24d0-48c0-bc15-0386bd284aa1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot: **Sergry**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Critical Analysis\n",
        "\n",
        "If you provide **bad examples**, the model will learn the **bad pattern**.\n",
        "This is why Data Quality in your prompt is just as important as code quality."
      ],
      "metadata": {
        "id": "OR2pzs2_lcgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit 2 - Part 2c: Advanced Templates & Theory\n",
        "\n",
        "## 1. Theory: Engineering vs. Training\n",
        "\n",
        "### Hard Prompts (Prompt Engineering)\n",
        "- **What:** You change the text input.\n",
        "- **Cost:** Cheap, fast, easy to iterate.\n",
        "- **Use Case:** Prototyping, General tasks.\n",
        "\n",
        "### Soft Prompts (Fine Tuning)\n",
        "- **What:** You change the model's internal weights (mathematically).\n",
        "- **Cost:** Expensive, slow, needs data.\n",
        "- **Use Case:** Domain specificity (Medical, Legal), Behavioral change."
      ],
      "metadata": {
        "id": "xga3HSA1leoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "7ucbxSSOlXxg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Dynamic Few-Shotting\n",
        "\n",
        "If you have 1000 examples, you can't fit them all in the context window.\n",
        "We use a **Selector** to pick the best ones.\n",
        "\n",
        "### The Selector Flow (Flowchart)\n",
        "```mermaid\n",
        "graph LR\n",
        "    Input[User Input] -->|Semantic Search| Database[Example Database]\n",
        "    Database -->|Top 3 Matches| Selector\n",
        "    Selector -->|Inject| Prompt\n",
        "```"
      ],
      "metadata": {
        "id": "Iv24oHuCliag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# Format of each example\n",
        "example_fmt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n",
        "\n",
        "# Example database\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"I want to stay in bed all day but I also feel guilty for being unproductive.\",\n",
        "        \"output\": \"Restlessponsible – A blended term describing the conflict between craving rest and feeling responsible for unfinished tasks.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"She keeps checking her phone even though she knows no new messages have arrived.\",\n",
        "        \"output\": \"Notifxious – A playful blend capturing the anxious anticipation of notifications that may not exist.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"He laughed at the joke but deep down he was slightly offended.\",\n",
        "        \"output\": \"Laughended – A creative expression describing the awkward mix of amusement and mild offense.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_fmt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a Corpo-Speak Translator\"),\n",
        "    few_shot_prompt,\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "chain = final_prompt | llm\n",
        "\n",
        "print(chain.invoke({\"text\": \"This app is annoying .\"}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2aRRslUlgvb",
        "outputId": "57c5324f-8f54-4fcf-e285-d227da63c54b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Appstration** – A blend of \"app\" and \"frustration,\" describing the feeling of annoyance or irritation caused by a poorly designed or malfunctioning application.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Analysis\n",
        "\n",
        "Using `FewShotChatMessagePromptTemplate` creates a clean separation between instructions and data. This helps the Attention Mechanism focus on the right things."
      ],
      "metadata": {
        "id": "5SXZkkc2lmQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "structured_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a Principal Python Engineer who writes highly maintainable, \"\n",
        "     \"well-tested, production-grade Python code with strong type hints.\"),\n",
        "\n",
        "    (\"human\",\n",
        "     \"Implement a Python function that reverses a string.\\n\\n\"\n",
        "     \"Technical Requirements:\\n\"\n",
        "     \"- You MUST use recursion\\n\"\n",
        "     \"- You MUST NOT use slicing\\n\"\n",
        "     \"- Do not use built-in reverse utilities\\n\"\n",
        "     \"- Include type hints\\n\"\n",
        "     \"- Handle edge cases properly\\n\\n\"\n",
        "     \"Code Quality Requirements:\\n\"\n",
        "     \"- Add comprehensive docstrings (Google style)\\n\"\n",
        "     \"- Keep it clean and readable\\n\"\n",
        "     \"- Follow PEP8 standards\\n\"\n",
        "     \"- Include example usage\")\n",
        "])\n",
        "\n",
        "chain = structured_prompt | llm\n",
        "\n",
        "print(chain.invoke({}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noFPxEo-lkfs",
        "outputId": "c00950a8-e2a3-4040-a640-0c575943f3fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As a Principal Python Engineer, I prioritize clarity, correctness, and adherence to specified constraints. This implementation uses a nested helper function to manage the recursive state (the current index) without exposing it to the public API, ensuring a clean and intuitive interface. The \"no slicing\" constraint is met by using index-based character access and integer arithmetic for the recursive calls.\n",
            "\n",
            "```python\n",
            "from typing import TypeGuard\n",
            "\n",
            "def reverse_string(s: str) -> str:\n",
            "    \"\"\"Reverses a string using recursion without using slicing or built-in utilities.\n",
            "\n",
            "    This function reverses the input string by recursively processing characters\n",
            "    from left to right and appending them to the result of the reversed\n",
            "    subsequent characters. It achieves this by using a helper function that\n",
            "    manages the current index, thereby avoiding string slicing.\n",
            "\n",
            "    Args:\n",
            "        s: The input string to be reversed.\n",
            "\n",
            "    Returns:\n",
            "        The reversed string.\n",
            "\n",
            "    Raises:\n",
            "        TypeError: If the input `s` is not a string.\n",
            "\n",
            "    Examples:\n",
            "        >>> reverse_string(\"hello\")\n",
            "        'olleh'\n",
            "        >>> reverse_string(\"Python\")\n",
            "        'nohtyP'\n",
            "        >>> reverse_string(\"\")\n",
            "        ''\n",
            "        >>> reverse_string(\"a\")\n",
            "        'a'\n",
            "        >>> reverse_string(\"racecar\")\n",
            "        'racecar'\n",
            "    \"\"\"\n",
            "    # Type check for input validation\n",
            "    if not isinstance(s, str):\n",
            "        raise TypeError(\"Input must be a string.\")\n",
            "\n",
            "    def _reverse_recursive_helper(current_str: str, index: int) -> str:\n",
            "        \"\"\"Helper function for recursive string reversal.\n",
            "\n",
            "        This function processes the string character by character from the\n",
            "        given index to the end, building the reversed string.\n",
            "\n",
            "        Args:\n",
            "            current_str: The original string being reversed.\n",
            "            index: The current index in 'current_str' to process.\n",
            "\n",
            "        Returns:\n",
            "            The reversed substring starting from 'index' to the end of 'current_str'.\n",
            "        \"\"\"\n",
            "        # Base case: If the index has reached or exceeded the length of the string,\n",
            "        # it means there are no more characters to process. Return an empty string\n",
            "        # as the building block for concatenation.\n",
            "        if index == len(current_str):\n",
            "            return \"\"\n",
            "\n",
            "        # Recursive step:\n",
            "        # 1. Recursively call the helper function for the next index (index + 1).\n",
            "        #    This call will eventually return the reversed portion of the string\n",
            "        #    that *follows* the character at the current 'index'.\n",
            "        # 2. Concatenate the character at the current 'index' (current_str[index])\n",
            "        #    to the *end* of the result from the recursive call. This effectively\n",
            "        #    moves the current character to its correct position in the final\n",
            "        #    reversed string.\n",
            "        return _reverse_recursive_helper(current_str, index + 1) + current_str[index]\n",
            "\n",
            "    # Initiate the recursive process from the beginning of the string (index 0).\n",
            "    return _reverse_recursive_helper(s, 0)\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    # Example Usage and Test Cases\n",
            "    print(\"--- String Reversal Examples ---\")\n",
            "\n",
            "    test_cases = [\n",
            "        (\"hello\", \"olleh\"),\n",
            "        (\"Python\", \"nohtyP\"),\n",
            "        (\"\", \"\"),  # Edge case: empty string\n",
            "        (\"a\", \"a\"),  # Edge case: single character string\n",
            "        (\"racecar\", \"racecar\"),\n",
            "        (\"Madam\", \"madaM\"),\n",
            "        (\"12345\", \"54321\"),\n",
            "        (\"!@#$\", \"$#@!\"),\n",
            "    ]\n",
            "\n",
            "    for input_str, expected_output in test_cases:\n",
            "        actual_output = reverse_string(input_str)\n",
            "        print(f\"Input: '{input_str}'\")\n",
            "        print(f\"Expected: '{expected_output}'\")\n",
            "        print(f\"Actual:   '{actual_output}'\")\n",
            "        print(f\"Result: {'PASS' if actual_output == expected_output else 'FAIL'}\\n\")\n",
            "\n",
            "    # Test error handling for non-string input\n",
            "    print(\"--- Error Handling Test ---\")\n",
            "    try:\n",
            "        reverse_string(123)  # type: ignore\n",
            "    except TypeError as e:\n",
            "        print(f\"Caught expected error: {e}\")\n",
            "    try:\n",
            "        reverse_string(None)  # type: ignore\n",
            "    except TypeError as e:\n",
            "        print(f\"Caught expected error: {e}\")\n",
            "    try:\n",
            "        reverse_string([\"list\"])  # type: ignore\n",
            "    except TypeError as e:\n",
            "        print(f\"Caught expected error: {e}\")\n",
            "\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEAOnMk_ln9n"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}